import os, json, joblib, numpy as np, sqlite3
from Bio import SeqIO
from sklearn.metrics.pairwise import cosine_similarity
from difflib import SequenceMatcher
from fpdf import FPDF
from collections import Counter
from datetime import datetime
import plotly.graph_objects as go
from plotly.offline import plot
from io import BytesIO

# === Load model artifacts ===
MODEL_DIR = os.path.join(os.path.dirname(__file__), "model")
best_model = joblib.load(os.path.join(MODEL_DIR, "best_model.pkl"))
scaler = joblib.load(os.path.join(MODEL_DIR, "scaler.pkl"))

with open(os.path.join(MODEL_DIR, "kmer_vocab.json")) as f:
    vocab_info = json.load(f)

K = vocab_info["K"]
VOCAB = vocab_info["VOCAB"]

def clean_sequence(seq):
    return ''.join([s for s in seq.upper() if s in "ACGT"])

def get_kmers(seq, k=3):
    return [seq[i:i+k] for i in range(len(seq)-k+1)]

def extract_features(seq):
    seq = clean_sequence(seq)
    kmers = get_kmers(seq, K)
    counts = Counter(kmers)
    vec = np.array([counts.get(k, 0) for k in VOCAB]).reshape(1, -1)
    return scaler.transform(vec)

def predict_sequence(seq):
    X = extract_features(seq)
    pred = best_model.predict(X)[0]
    proba = best_model.predict_proba(X)[0]
    confidence = float(max(proba))
    return {"prediction": str(pred), "confidence": confidence, "probabilities": proba.tolist()}

def compare_sequences(seq1, seq2):
    """Return cosine + sequence similarity between two DNA sequences"""
    vec1 = extract_features(seq1)
    vec2 = extract_features(seq2)
    cosine_sim = float(cosine_similarity(vec1, vec2)[0][0])
    seq_sim = SequenceMatcher(None, seq1, seq2).ratio()
    
    # Calculate percentage similarity
    avg_similarity = (cosine_sim + seq_sim) / 2 * 100
    
    return {
        "cosine_similarity": cosine_sim,
        "sequence_similarity": seq_sim,
        "percentage_similarity": round(avg_similarity, 2)
    }

def detect_mutations(seq1, seq2):
    """Detects mutations (differences) between two sequences"""
    mutations = [(i, a, b) for i, (a, b) in enumerate(zip(seq1, seq2)) if a != b]
    return {"mutation_count": len(mutations), "mutations": mutations[:20]}  # limit to first 20 for readability

def generate_report(result_data, output_path="forensic_report.pdf"):
    """Generate a comprehensive forensic report in PDF format"""
    pdf = FPDF()
    pdf.add_page()
    
    # Header
    pdf.set_font("Arial", "B", 20)
    pdf.cell(0, 15, "DNA FORENSIC ANALYSIS REPORT", ln=True, align="C")
    pdf.ln(5)
    
    # Timestamp
    pdf.set_font("Arial", "", 10)
    pdf.cell(0, 8, f"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", ln=True, align="R")
    pdf.ln(10)
    
    # Sample Information
    pdf.set_font("Arial", "B", 14)
    pdf.cell(0, 10, "SAMPLE INFORMATION", ln=True)
    pdf.set_font("Arial", "", 11)
    
    for key, value in result_data.items():
        if isinstance(value, dict):
            pdf.multi_cell(0, 6, f"{key}: {json.dumps(value, indent=2)}")
        else:
            pdf.multi_cell(0, 6, f"{key}: {value}")
        pdf.ln(2)
    
    # Footer
    pdf.ln(20)
    pdf.set_font("Arial", "I", 8)
    pdf.cell(0, 8, "This report is generated by AI-powered DNA Analysis System", ln=True, align="C")
    
    pdf.output(output_path)
    return output_path

# === DATABASE FUNCTIONS ===
def init_database():
    """Initialize SQLite database for storing DNA analysis results"""
    conn = sqlite3.connect('dna_forensics.db')
    cursor = conn.cursor()
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS dna_analysis (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp TEXT,
            investigator_name TEXT,
            sample_name TEXT,
            dna_sequence TEXT,
            prediction TEXT,
            confidence REAL,
            similarity_results TEXT,
            mutations TEXT
        )
    ''')
    
    conn.commit()
    conn.close()

def save_to_database(data):
    """Save analysis results to database"""
    conn = sqlite3.connect('dna_forensics.db')
    cursor = conn.cursor()
    
    cursor.execute('''
        INSERT INTO dna_analysis 
        (timestamp, investigator_name, sample_name, dna_sequence, prediction, confidence, similarity_results, mutations)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
    ''', (
        datetime.now().isoformat(),
        data.get('investigator_name', 'Unknown'),
        data.get('sample_name', 'Sample'),
        data.get('dna_sequence', ''),
        data.get('prediction', ''),
        data.get('confidence', 0.0),
        json.dumps(data.get('similarity_results', {})),
        json.dumps(data.get('mutations', {}))
    ))
    
    conn.commit()
    conn.close()

def get_analysis_history():
    """Retrieve analysis history from database"""
    conn = sqlite3.connect('dna_forensics.db')
    cursor = conn.cursor()
    
    cursor.execute('SELECT * FROM dna_analysis ORDER BY timestamp DESC LIMIT 50')
    results = cursor.fetchall()
    
    conn.close()
    return results

# === VISUALIZATION FUNCTIONS ===
def create_similarity_chart(similarity_data):
    """Create similarity comparison chart"""
    fig = go.Figure(data=[
        go.Bar(
            x=['Cosine Similarity', 'Sequence Similarity', 'Overall Similarity'],
            y=[
                similarity_data.get('cosine_similarity', 0) * 100,
                similarity_data.get('sequence_similarity', 0) * 100,
                similarity_data.get('percentage_similarity', 0)
            ],
            marker_color=['#FF6B6B', '#4ECDC4', '#45B7D1']
        )
    ])
    
    fig.update_layout(
        title="DNA Similarity Analysis",
        yaxis_title="Similarity Percentage (%)",
        xaxis_title="Similarity Metrics"
    )
    
    return plot(fig, output_type='div', include_plotlyjs=False)

def create_confidence_pie_chart(probabilities, class_names=None):
    """Create confidence pie chart for predictions"""
    if not class_names:
        class_names = [f"Class {i}" for i in range(len(probabilities))]
    
    fig = go.Figure(data=[go.Pie(
        labels=class_names,
        values=probabilities,
        hole=0.3
    )])
    
    fig.update_layout(title="Prediction Confidence Distribution")
    return plot(fig, output_type='div', include_plotlyjs=False)

def create_kmer_frequency_chart(sequence):
    """Create k-mer frequency bar chart"""
    kmers = get_kmers(clean_sequence(sequence), K)
    kmer_counts = Counter(kmers)
    
    # Get top 20 most frequent k-mers
    top_kmers = dict(kmer_counts.most_common(20))
    
    fig = go.Figure(data=[
        go.Bar(x=list(top_kmers.keys()), y=list(top_kmers.values()))
    ])
    
    fig.update_layout(
        title=f"Top 20 {K}-mer Frequencies",
        xaxis_title="K-mers",
        yaxis_title="Frequency"
    )
    
    return plot(fig, output_type='div', include_plotlyjs=False)

# === CONFIDENCE-BASED FILTERING ===
def assess_confidence(confidence_score, threshold=0.70):
    """Assess if sample needs re-testing based on confidence"""
    if confidence_score < threshold:
        return {
            "status": "NEEDS_RETESTING",
            "message": f"Low confidence ({confidence_score:.2%}). Sample requires re-testing.",
            "recommendation": "Consider collecting additional DNA sample or using alternative analysis methods."
        }
    else:
        return {
            "status": "RELIABLE",
            "message": f"High confidence ({confidence_score:.2%}). Results are reliable.",
            "recommendation": "Analysis results can be used for forensic purposes."
        }

# === MULTIPLE INPUT FORMAT SUPPORT ===
def parse_dna_input(file_content, filename):
    """Parse DNA input from various formats"""
    try:
        # Auto-detect format based on content and filename
        if filename.endswith('.fasta') or filename.endswith('.fa'):
            # Parse FASTA format
            sequences = []
            for record in SeqIO.parse(BytesIO(file_content), "fasta"):
                sequences.append(str(record.seq))
            return sequences[0] if sequences else None
        
        elif filename.endswith('.txt'):
            # Parse plain text
            content = file_content.decode('utf-8').strip()
            return clean_sequence(content)
        
        else:
            # Try to parse as plain sequence
            content = file_content.decode('utf-8').strip()
            return clean_sequence(content)
    
    except Exception as e:
        return None

# === LEVENSHTEIN DISTANCE FOR DNA SIMILARITY ===
def levenshtein_distance(seq1, seq2):
    """Calculate Levenshtein distance between two sequences"""
    if len(seq1) < len(seq2):
        return levenshtein_distance(seq2, seq1)
    
    if len(seq2) == 0:
        return len(seq1)
    
    previous_row = list(range(len(seq2) + 1))
    for i, c1 in enumerate(seq1):
        current_row = [i + 1]
        for j, c2 in enumerate(seq2):
            insertions = previous_row[j + 1] + 1
            deletions = current_row[j] + 1
            substitutions = previous_row[j] + (c1 != c2)
            current_row.append(min(insertions, deletions, substitutions))
        previous_row = current_row
    
    return previous_row[-1]

def advanced_similarity_analysis(seq1, seq2):
    """Advanced similarity analysis using multiple algorithms"""
    # Clean sequences
    seq1_clean = clean_sequence(seq1)
    seq2_clean = clean_sequence(seq2)
    
    # Cosine similarity
    vec1 = extract_features(seq1_clean)
    vec2 = extract_features(seq2_clean)
    cosine_sim = float(cosine_similarity(vec1, vec2)[0][0])
    
    # Sequence matcher similarity
    seq_sim = SequenceMatcher(None, seq1_clean, seq2_clean).ratio()
    
    # Levenshtein similarity
    lev_distance = levenshtein_distance(seq1_clean, seq2_clean)
    max_len = max(len(seq1_clean), len(seq2_clean))
    lev_similarity = 1 - (lev_distance / max_len) if max_len > 0 else 0
    
    # Combined similarity score
    combined_similarity = (cosine_sim + seq_sim + lev_similarity) / 3 * 100
    
    return {
        "cosine_similarity": round(cosine_sim * 100, 2),
        "sequence_similarity": round(seq_sim * 100, 2),
        "levenshtein_similarity": round(lev_similarity * 100, 2),
        "combined_similarity": round(combined_similarity, 2),
        "match_quality": "EXCELLENT" if combined_similarity > 95 else 
                        "GOOD" if combined_similarity > 85 else
                        "MODERATE" if combined_similarity > 70 else "POOR"
    }

# Initialize database on import
init_database()